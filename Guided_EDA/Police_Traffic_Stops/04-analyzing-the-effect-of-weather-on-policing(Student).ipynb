{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><p style=\"text-align: center;\">Data Analysis with Python <br>Project - 1</p><h1> - Traffic Police Stops <img src=\"https://docs.google.com/uc?id=17CPCwi3_VvzcS87TOsh4_U8eExOhL6Ki\" class=\"img-fluid\" alt=\"CLRSWY\" width=\"200\" height=\"100\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, you will use a **second dataset** to explore the impact of **weather conditions** on police behavior during traffic stops. You will practice **merging** and **reshaping** datasets, assessing whether a data source is trustworthy, working with **categorical** data, and other advanced skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the temperature"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this exercise, you'll examine the ``temperature`` columns from the ``weather`` dataset to assess whether the data seems trustworthy. First you'll print the summary statistics, and then you'll visualize the data using a **box plot**.\n",
    "\n",
    "When deciding whether the values seem reasonable, keep in mind that the temperature is measured in degrees **Fahrenheit**, not Celsius!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\n",
    "\n",
    "*   Read ``weather.csv`` into a ``DataFrame`` named ``weather``.\n",
    "*   Select the temperature columns (``TMIN``, ``TAVG``, ``TMAX``) and print their ``summary statistics`` using the ``.describe()`` method.\n",
    "*   Create a **box plot** to visualize the temperature columns.\n",
    "*   Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"weather.csv\")\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[[\"TMIN\",\"TAVG\",\"TMAX\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = weather[[\"TMIN\",\"TAVG\",\"TMAX\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.plot(kind = \"box\", figsize = (20,14));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the temperature difference"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this exercise, you'll continue to assess ``whether`` the dataset seems trustworthy by plotting the difference between the maximum and minimum temperatures.\n",
    "\n",
    "What do you notice about the resulting **histogram**? Does it match your expectations, or do you see anything unusual?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\n",
    "\n",
    "*   Create a new column in the ``weather`` ``DataFrame`` named ``TDIFF`` that represents the difference between the maximum and minimum temperatures.\n",
    "*   Print the summary statistics for ``TDIFF`` using the ``.describe()`` method.\n",
    "*   Create a histogram with ``20 bins`` to visualize ``TDIFF``.\n",
    "*   Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"TDIFF\"] = weather[\"TMAX\"] - weather[\"TMIN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"TDIFF\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"TDIFF\"].plot(kind = \"hist\" , bins = 20 , figsize = (20,14));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting bad weather conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``weather`` ``DataFrame`` contains ``20`` columns that start with ``'WT'``, each of which represents a bad weather condition. For example:\n",
    "\n",
    "*   ``WT05`` indicates ``\"Hail\"``\n",
    "*   ``WT11`` indicates ``\"High or damaging winds\"``\n",
    "*   ``WT17`` indicates ``\"Freezing rain\"``\n",
    "\n",
    "For every row in the dataset, each ``WT`` column contains either a ``1`` (meaning the condition was present that day) or ``NaN`` (meaning the condition was not present).\n",
    "\n",
    "In this exercise, you'll quantify ``\"how bad\"`` the weather was each day by counting the number of ``1`` values in each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\n",
    "\n",
    "*   Copy the columns ``WT01`` through ``WT22`` from ``weather`` to a new ``DataFrame`` named ``WT``.\n",
    "*   Calculate the sum of each row in ``WT``, and store the results in a new weather column named ``bad_conditions``.\n",
    "*   Replace any ``missing values`` in ``bad_conditions`` with a ``0``. (This has been done for you.)\n",
    "*   Create a **histogram** to visualize ``bad_conditions``, and then display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT = weather.loc[:,\"WT01\" : \"WT22\"]\n",
    "WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"bad_conditions\"] = WT.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"bad_conditions\"].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"bad_conditions\"].plot(kind = \"hist\" , figsize = (20,14));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusions #\n",
    "# Weather of days usually clear and good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating the weather conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, you counted the number of bad weather conditions each day. In this exercise, you'll use the counts to create a *rating system** for the weather.\n",
    "\n",
    "The counts range from ``0`` to ``9``, and should be converted to ratings as follows:\n",
    "\n",
    "*   Convert ``0`` to ``'good'``\n",
    "*   Convert ``1`` through ``4`` to ``'bad'``\n",
    "*   Convert ``5`` through ``9`` to ``'worse'``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\n",
    "\n",
    "*   Count the **unique** values in the ``bad_conditions`` column and sort the ``index``. \n",
    "*   Create a ``dictionary`` called ``mapping`` that maps the ``bad_conditions`` integers to strings as specified above.\n",
    "*   Convert the ``bad_conditions`` integers to strings using the ``mapping`` and store the results in a new column called ``rating``.\n",
    "*   Count the **unique** values in ``rating`` to verify that the integers were properly converted to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"bad_conditions\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"rating\"] = weather[\"bad_conditions\"].apply(lambda x : 'good' if x == 0 else('bad' if 1<= x <=4 else 'worse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the data type to category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ``rating`` column only has a few possible values, you'll change its data type to ``category`` in order to store the data more efficiently. You'll also specify a logical order for the categories, which will be useful for future exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\n",
    "\n",
    "*   Create a ``list`` object called ``cats`` that lists the weather ratings in a logical order: ``'good'``, ``'bad'``, ``'worse'``.\n",
    "*   Change the data type of the ``rating`` column from ``object`` to ``category``. Make sure to use the ``cats list`` to define the category ordering.\n",
    "*   Examine the ``head`` of the ``rating`` column to confirm that the categories are logically ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['good' , 'bad' , \"worse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"rating\"] = weather[\"rating\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll prepare the **traffic stop** and **weather rating** ``DataFrames`` so that they're ready to be merged:\n",
    "\n",
    "With the ``ri`` ``DataFrame``, you'll move the ``stop_datetime`` index to a ``column`` since the index will be lost during the merge.\n",
    "\n",
    "With the ``weather`` ``DataFrame``, you'll select the ``DATE`` and ``rating`` columns and put them in a new ``DataFrame``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\n",
    "\n",
    "* Reset the ``index`` of the ``ri`` ``DataFrame``.\n",
    "\n",
    "* Examine the ``head`` of ``ri`` to verify that ``stop_datetime`` is now a ``DataFrame`` column, \n",
    "and the ``index`` is now the default ``integer`` index.\n",
    "\n",
    "* Create a new ``DataFrame`` named ``weather_rating`` that contains only the ``DATE`` and ``rating`` columns from the ``weather`` ``DataFrame``.\n",
    "\n",
    "* Examine the ``head`` of ``weather_rating`` to verify that it contains the proper columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Before starting your work from this part of this chapter **repeat the steps which you did in the first chapter for preparing the ``ri`` data.** Continue to this chapter based on where you were in the end of the first chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri = pd.read_csv(\"police4.csv\", low_memory=False)\n",
    "ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_rating = weather[[\"DATE\",\"rating\"]]\n",
    "weather_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the DataFrames\n",
    "In this exercise, you'll ``merge`` the ``ri`` and ``weather_rating`` ``DataFrames`` into a new ``DataFrame``, ``ri_weather``.\n",
    "\n",
    "The ``DataFrames`` will be joined using the ``stop_date`` column from ``ri`` and the ``DATE`` column from ``weather_rating``. Thankfully the date formatting matches exactly, which is not always the case!\n",
    "\n",
    "Once the merge is complete, you'll set ``stop_datetime`` as the index, which is the column you saved in the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the shape of the ``ri`` ``DataFrame``.\n",
    "``Merge`` the ``ri`` and ``weather_rating`` ``DataFrames`` using a ``left join``.\n",
    "Examine the ``shape`` of ``ri_weather`` to confirm that it has two more columns but the same number of rows as ``ri``.\n",
    "Replace the ``index`` of ``ri_weather`` with the ``stop_datetime`` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_rating[\"DATE\"].value_counts() # Dates not unique. That will be problem when we merge..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_rating.drop_duplicates(subset=\"DATE\" , inplace=True) # If we drop duplicates that won't be good result. But same if we don't drop... I won't drop. That will give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_rating[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_weather = pd.merge(left = ri , right = weather_rating , left_on=\"stop_date\" , right_on = \"DATE\" , how = \"left\")\n",
    "# ri_weather.drop_duplicates(subset = \"id\" , inplace=True) # I also shoul'nt drop duplicates after merge too.\n",
    "ri_weather.set_index(\"stop_datetime\" , inplace=True , drop=True)\n",
    "ri_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_weather[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing arrest rates by weather rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do police officers arrest drivers more often when the weather is bad? Find out below!\n",
    "\n",
    "- **First**, you'll calculate the **overall arrest rate**.\n",
    "\n",
    "- **Then**, you'll calculate the **arrest rate** for each of the **weather ratings** you previously assigned.\n",
    "\n",
    "- **Finally**, you'll add **violation type** as a second factor in the analysis, to see if that accounts for any differences in the arrest rate.\n",
    "\n",
    "Since you previously defined a logical order for the weather categories, ``good < bad < worse``, they will be sorted that way in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_weather[\"is_arrested\"].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_weather.groupby(\"rating\").mean()[\"is_arrested\"].sort_values() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_weather.groupby([\"rating\",\"violation\"]).mean()[\"is_arrested\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrest rate 3.93 on worse days. 3.52 bad days , and 3.4 good days.\n",
    "# Looking weather affect police officers behaviour a little bit.\n",
    "# When we add second factor violation. Looks also same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting From a mult-indexed Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of a single ``.groupby()`` operation on multiple columns is a ``Series`` with a ``MultiIndex``. Working with this type of object is similar to working with a ``DataFrame``:\n",
    "\n",
    "The ``outer`` index level is like the ``DataFrame`` rows.\n",
    "The ``inner`` index level is like the ``DataFrame`` columns.\n",
    "In this exercise, you'll practice accessing data from a multi-indexed ``Series`` using the ``.loc[]`` accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\n",
    "\n",
    "- Save the output of the ``.groupby()`` operation from the last exercise as a new object, ``arrest_rate``.\n",
    "- Print the ``arrest_rate`` ``Series`` and examine it.\n",
    "- Print the arrest rate for ``moving violations`` in bad weather.\n",
    "- Print the arrest rates for ``speeding violations`` in all three weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_rate = ri_weather.groupby([\"violation\",\"rating\"])[\"is_arrested\"].mean() * 100\n",
    "arrest_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_rate.loc[\"Moving violation\" , \"bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_rate.loc[\"Speeding\" , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusions #\n",
    "# There is no any realated between weather and speeding arrest rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the arrest rate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll start by **reshaping** the ``arrest_rate`` ``Series`` into a ``DataFrame``. This is a useful step when working with any multi-indexed ``Series``, since it enables you to access the full range of ``DataFrame`` methods.\n",
    "\n",
    "Then, you'll create the exact same ``DataFrame`` using a ``pivot table``. This is a great example of how pandas often gives you more than one way to reach the same result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\n",
    "\n",
    "- ``unstack`` the ``arrest_rate`` ``Series`` to ``reshape`` it into a ``DataFrame``.\n",
    "- Create the exact same ``DataFrame`` using a ``pivot table``! Each of the three ``.pivot_table()`` parameters should be specified as one of the ``ri_weather`` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_rate.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_weather.pivot_table(index = \"violation\" , columns=\"rating\" , values = \"is_arrested\") * 100 # Exactly same DF with .unstack() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusions # \n",
    "# I learnt too many things with this EDA process.\n",
    "# I had only one problem when I try to merge with ri and weather DataFrames. Because wheather dates was'nt unique...\n",
    "# EDA done. Thanks. !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d8cd8638caa719e77c3ece9ee6c9cdab6f2065d170551d375a17b4273bc3a23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
