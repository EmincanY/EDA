{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Functions for EDA or Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanShower(df,percentage) :\n",
    "    for col in df.columns : \n",
    "        if df[col].isna().sum() > df[col].count() * percentage//100 :\n",
    "            print(f'{col} column has {df[col].isna().sum()} nan values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanDeleter(df,percentage) :\n",
    "    for col in df.columns : \n",
    "        if df[col].isna().sum() > df[col].count() * percentage//100 :\n",
    "            print(f'{col} column has deleted because {df[col].isna().sum()} nan values')\n",
    "            df.drop(col , axis = 1 , inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_class(df):\n",
    "    for col in df.columns:\n",
    "        if len(df[col].value_counts()) == 1 :\n",
    "            print(f\"{col} column has only 1 class\")\n",
    "            print(df[col].value_counts(), end = '\\n\\n\\n')\n",
    "        elif len(df[col].value_counts()) == 2 :\n",
    "            print(f\"{col} column has only 2 class\")\n",
    "            print(df[col].value_counts(), end = '\\n\\n\\n')\n",
    "        elif len(df[col].value_counts()) == 3 :\n",
    "            print(f\"{col} column has only 3 class\")\n",
    "            print(df[col].value_counts(), end = '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardClass_cols = []\n",
    "\n",
    "def hardClass(df,percentage) :\n",
    "    for col in df.columns : \n",
    "        for n_class in df[col].value_counts():\n",
    "            if n_class > df[col].count() * percentage // 100:\n",
    "                print(f'{col} column has a hard class. {n_class} in one class')\n",
    "                hardClass_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continousFeatures(df,num):\n",
    "    for col in df.columns : \n",
    "        if len(df[col].value_counts()) > num : \n",
    "            print(f'{col} column continous feature. Because has {df[col].nunique()} different value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNumber_Many = []\n",
    "\n",
    "def classNumber(df , num) :\n",
    "    for cat_col in df.select_dtypes('object').columns : \n",
    "        if df[cat_col].value_counts().nunique() > num : \n",
    "            print(f'{cat_col} categoric feature has {df[cat_col].value_counts().nunique()} different class.')\n",
    "            classNumber_Many.append(cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_teller(df,target_col , whisker):\n",
    "  for col in df.drop(target_col , axis = 1).columns : \n",
    "    if df[col].dtype != 'object':\n",
    "      q3 =  np.percentile(df[col] , 75)\n",
    "      q1 =  np.percentile(df[col] , 25)\n",
    "\n",
    "      iqr = q3 - q1\n",
    "      low_lim = q1 - (whisker*iqr)\n",
    "      high_lim = q3 + (whisker*iqr)\n",
    "\n",
    "      outlier_indexes = df[ (df[col] > high_lim) | (df[col] < low_lim) ].index\n",
    "      print(f'Total outlier {len(outlier_indexes)} in {col} column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_deleter(df,target_col , whisker):\n",
    "  for col in df.drop(target_col , axis = 1).columns : \n",
    "    if df[col].dtype != 'object':\n",
    "      q3 =  np.percentile(df[col] , 75)\n",
    "      q1 =  np.percentile(df[col] , 25)\n",
    "\n",
    "      iqr = q3 - q1\n",
    "      low_lim = q1 - (whisker*iqr)\n",
    "      high_lim = q3 + (whisker*iqr)\n",
    "\n",
    "      outlier_indexes = df[ (df[col] > high_lim) | (df[col] < low_lim) ].index\n",
    "      df.drop(outlier_indexes , axis = 0 , inplace = True)\n",
    "      print(f'Total outlier {len(outlier_indexes)} in {col} column and dropped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, plot_confusion_matrix\n",
    "\n",
    "def eval_metric(model, X_train, X_test, y_train, y_test):\n",
    "    plot_confusion_matrix(model, X_test, y_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    print(classification_report(y_test, y_pred), end='\\n')\n",
    "    print(\"Train Set\")\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score , mean_absolute_error , mean_squared_error\n",
    "\n",
    "def eval_metric(model, X_train, X_test, y_train, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    test_r2 = r2_score(y_test , y_pred)\n",
    "    test_mae = mean_absolute_error(y_test , y_pred)\n",
    "    test_rmse = mean_squared_error(y_test , y_pred) ** 0.5\n",
    "    \n",
    "    train_r2 = r2_score(y_train , y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train , y_train_pred)\n",
    "    train_rmse = mean_squared_error(y_train , y_train_pred) ** 0.5\n",
    "    \n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    print(f'r2 score : {test_r2}\\nmae : {test_mae}\\nrmse : {test_rmse}\\n\\n\\n')\n",
    "    print(\"Train Set\")\n",
    "    print(f'r2 score : {train_r2}\\nmae : {train_mae}\\nrmse : {train_rmse}\\n\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d8cd8638caa719e77c3ece9ee6c9cdab6f2065d170551d375a17b4273bc3a23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
